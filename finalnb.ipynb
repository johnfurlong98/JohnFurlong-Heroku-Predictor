{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the House Price Prediction Process\n",
    "\n",
    "Below is a comprehensive overview of the entire workflow, incorporating key aspects of the dataset’s features, transformations, modeling, and predictions. This explanation aims to provide clarity on each step, including the rationale behind certain decisions, and to highlight the professional approach used in preparing a reliable house price prediction model. I have condensed everything into one cell to improve performance during deployment and have left out some of the visualizations that I used when training and evaluating the model as they are in the dashboard.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Features and Their Definitions\n",
    "\n",
    "The model leverages a variety of features extracted from housing records. Each feature contributes to the understanding of a home’s potential market value. Below are some of the core features used, along with their ranges and definitions:\n",
    "\n",
    "- **1stFlrSF (First Floor SF):**  \n",
    "  *Range:* 334 – 4692  \n",
    "  *Description:* Total square feet of the house’s first floor living area.\n",
    "  \n",
    "- **2ndFlrSF (Second Floor SF):**  \n",
    "  *Range:* 0 – 2065  \n",
    "  *Description:* Total square feet of the house’s second floor living area.\n",
    "  \n",
    "- **BedroomAbvGr (Bedrooms Above Grade):**  \n",
    "  *Range:* 0 – 8  \n",
    "  *Description:* Number of bedrooms above ground level (excludes basement bedrooms).\n",
    "  \n",
    "- **BsmtExposure (Basement Exposure):**  \n",
    "  *Categories:* None (No Basement), No, Mn, Av, Gd  \n",
    "  *Description:* Describes walkout or garden-level basement walls. Higher categories (e.g., Gd) indicate better exposure.\n",
    "  \n",
    "- **BsmtFinType1 (Basement Finish Type):**  \n",
    "  *Categories:* None (No Basement), Unf, LwQ, Rec, BLQ, ALQ, GLQ  \n",
    "  *Description:* Indicates the finish quality of the basement, from unfinished (Unf) to high-quality living quarters (GLQ).\n",
    "  \n",
    "- **BsmtFinSF1 (Type 1 Finished Basement SF):**  \n",
    "  *Range:* 0 – 5644  \n",
    "  *Description:* Finished basement area in square feet.\n",
    "  \n",
    "- **BsmtUnfSF (Unfinished Basement SF):**  \n",
    "  *Range:* 0 – 2336  \n",
    "  *Description:* Unfinished portion of the basement area in square feet.\n",
    "  \n",
    "- **TotalBsmtSF (Total Basement SF):**  \n",
    "  *Range:* 0 – 6110  \n",
    "  *Description:* Total basement area in square feet.\n",
    "  \n",
    "- **GarageArea (Garage Area):**  \n",
    "  *Range:* 0 – 1418  \n",
    "  *Description:* Size of the garage in square feet.\n",
    "  \n",
    "- **GarageFinish (Garage Finish Quality):**  \n",
    "  *Categories:* None (No Garage), Unf, RFn, Fin  \n",
    "  *Description:* Interior finish level of the garage.\n",
    "  \n",
    "- **GarageYrBlt (Garage Year Built):**  \n",
    "  *Range:* 1900 – 2010  \n",
    "  *Description:* The year the garage was constructed.\n",
    "  \n",
    "- **GrLivArea (Above Grade Living Area):**  \n",
    "  *Range:* 334 – 5642  \n",
    "  *Description:* Total above-ground (non-basement) living area square feet.\n",
    "  \n",
    "- **KitchenQual (Kitchen Quality):**  \n",
    "  *Categories:* Po, Fa, TA, Gd, Ex  \n",
    "  *Description:* Rates the kitchen’s quality from poor (Po) to excellent (Ex).\n",
    "  \n",
    "- **LotArea (Lot Size):**  \n",
    "  *Range:* 1300 – 215245  \n",
    "  *Description:* Total lot size in square feet.\n",
    "  \n",
    "- **LotFrontage (Street Frontage):**  \n",
    "  *Range:* 21 – 313  \n",
    "  *Description:* Linear feet of street connected to the property.\n",
    "  \n",
    "- **MasVnrArea (Masonry Veneer Area):**  \n",
    "  *Range:* 0 – 1600  \n",
    "  *Description:* Square feet of masonry veneer on the exterior of the home.\n",
    "  \n",
    "- **EnclosedPorch (Enclosed Porch Area):**  \n",
    "  *Range:* 0 – 286  \n",
    "  *Description:* Total enclosed porch area in square feet.\n",
    "  \n",
    "- **OpenPorchSF (Open Porch Area):**  \n",
    "  *Range:* 0 – 547  \n",
    "  *Description:* Total open porch area in square feet.\n",
    "  \n",
    "- **OverallCond (Overall Condition):**  \n",
    "  *Range:* 1 (Very Poor) – 10 (Very Excellent)  \n",
    "  *Description:* Rates the overall condition of the house.\n",
    "  \n",
    "- **OverallQual (Overall Quality):**  \n",
    "  *Range:* 1 (Very Poor) – 10 (Very Excellent)  \n",
    "  *Description:* Rates the overall material and finish of the house.\n",
    "  \n",
    "- **WoodDeckSF (Wood Deck Area):**  \n",
    "  *Range:* 0 – 736  \n",
    "  *Description:* Total wood deck area in square feet.\n",
    "  \n",
    "- **YearBuilt (Year Built):**  \n",
    "  *Range:* 1872 – 2010  \n",
    "  *Description:* Year the property was originally constructed.\n",
    "  \n",
    "- **YearRemodAdd (Year Remodeled):**  \n",
    "  *Range:* 1950 – 2010  \n",
    "  *Description:* Year the house was remodeled or had an addition. If no remodeling occurred, it’s the year built.\n",
    "  \n",
    "- **SalePrice (Target Variable):**  \n",
    "  *Range:* 34900 – 755000  \n",
    "  *Description:* The actual sale price of the property, serving as the target variable for model training.\n",
    "\n",
    "---\n",
    "\n",
    "### Process Overview\n",
    "\n",
    "**Key Inputs:**  \n",
    "- **House Sales Historical Data:** Contains the above features and the `SalePrice` for a large number of properties.  \n",
    "- **Inherited Houses Data:** Similar structure but without known `SalePrice`, used for producing price predictions.\n",
    "\n",
    "**Major Steps:**\n",
    "\n",
    "1. **Data Loading & Initial Inspection:**  \n",
    "   **Input:** Raw CSV files.  \n",
    "   **Process:** Read into Pandas, confirm shapes, and inspect initial rows.  \n",
    "   **Output:** Two DataFrames ready for preprocessing (`house_data`, `inherited_houses`).\n",
    "\n",
    "2. **Preprocessing & Missing Values:**  \n",
    "   **Input:** Raw datasets with potential missing data.  \n",
    "   **Process:**  \n",
    "   - Impute zero for features logically zero if missing (e.g., `EnclosedPorch`).  \n",
    "   - Fill categorical missing values with mode or appropriate defaults (`KitchenQual` → ‘TA’).  \n",
    "   - Fill numeric gaps with median values as needed.  \n",
    "   \n",
    "   These steps produce complete, consistent datasets suitable for modeling.  \n",
    "   **Output:** Cleaned DataFrames with no missing values.\n",
    "\n",
    "3. **Data Transformations (Normalization & Encoding):**  \n",
    "   **Input:** Cleaned DataFrames.  \n",
    "   **Process:**  \n",
    "   - Apply `log1p` or Box-Cox transformations to right-skewed features (including `SalePrice`) for more stable distributions.  \n",
    "   - Ordinally encode categorical features (e.g., `BsmtExposure`, `KitchenQual`) to preserve meaningful order.  \n",
    "   \n",
    "   **Output:** DataFrames with normalized numeric features and encoded categorical variables.\n",
    "\n",
    "4. **Feature Engineering:**  \n",
    "   **Input:** Transformed DataFrames.  \n",
    "   **Process:**  \n",
    "   - Create `TotalSF` (sum of basement and above-grade areas) and `Qual_TotalSF` (Overall Quality × TotalSF) to capture additional value-driven relationships.  \n",
    "   \n",
    "   **Output:** Enhanced feature sets that potentially improve predictive accuracy.\n",
    "\n",
    "5. **Feature Selection:**  \n",
    "   **Input:** DataFrames with multiple potential predictors.  \n",
    "   **Process:**  \n",
    "   - Use a preliminary Random Forest to gauge feature importance.  \n",
    "   - Select the most predictive features to simplify the model and potentially boost performance.  \n",
    "   \n",
    "   **Output:** A refined set of selected features (`selected_features.pkl`) for the final model.\n",
    "\n",
    "6. **Model Training & Evaluation:**  \n",
    "   **Input:** Selected features and log-transformed target (`SalePrice_Log`).  \n",
    "   **Process:**  \n",
    "   - Split the data into training and test sets.  \n",
    "   - Scale features for linear models.  \n",
    "   - Train several models (Linear, Ridge, Lasso, ElasticNet, Gradient Boosting, Random Forest, XGBoost) and compare performance using MAE, RMSE, and R².  \n",
    "   \n",
    "   **Output:**  \n",
    "   - Trained models saved as joblib files.  \n",
    "   - Evaluation metrics stored in CSV.  \n",
    "   - Identification of the best model for final deployment.\n",
    "\n",
    "7. **Predicting on Inherited Houses:**  \n",
    "   **Input:** `inherited_houses` dataset processed identically to training data.  \n",
    "   **Process:**  \n",
    "   - Apply the same cleaning, encoding, scaling, and feature selection steps.  \n",
    "   - Use trained models to predict house prices (in transformed scale, then converted back to the original scale).  \n",
    "   \n",
    "   **Output:** A CSV file containing predictions for the inherited houses and a `final_model.joblib` representing the best-performing model.\n",
    "\n",
    "---\n",
    "\n",
    "### Overall Rationale & Professional Approach\n",
    "\n",
    "- **Imputation & Transformation Choices:** Ensures robust modeling and prevents data leakage or bias.  \n",
    "- **Ordinal Encoding & Feature Engineering:** Incorporates domain knowledge and logical structures into the dataset, improving signal strength.  \n",
    "- **Multiple Models & Thorough Evaluation:** Encourages evidence-based selection of the best algorithm, rather than relying on a single approach.  \n",
    "- **Reproducibility & Documentation:** All intermediate artifacts (e.g., scalers, selected features, trained models) are saved for transparency, reproducibility, and future maintenance.\n",
    "\n",
    "In sum, this process exemplifies a structured, professional, and scalable approach to building a predictive model. It leverages domain insights, maintains rigorous standards for data handling, and ensures that the final product is both reliable and easily integrable into a real-world pricing scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# house_price_prediction.ipynb\n",
    "\n",
    "# Import essential libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, ElasticNetCV, LassoCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "# Ignore warnings for clean output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set BASE_DIR to the current working directory for Jupyter Notebooks\n",
    "BASE_DIR = Path(os.getcwd())\n",
    "\n",
    "# Define directories\n",
    "data_dir = BASE_DIR / 'data'\n",
    "models_dir = BASE_DIR / 'data' / 'models'  # Subdirectory for models\n",
    "os.makedirs(models_dir, exist_ok=True)  # Ensure models directory exists\n",
    "\n",
    "# Set file paths\n",
    "house_data_file = BASE_DIR /'raw_data' / 'house_prices_records.csv'\n",
    "inherited_houses_file = BASE_DIR / 'raw_data' / 'inherited_houses.csv'\n",
    "\n",
    "# Import datasets\n",
    "house_data = pd.read_csv(house_data_file)\n",
    "inherited_houses = pd.read_csv(inherited_houses_file)\n",
    "\n",
    "print(f\"House Data Shape: {house_data.shape}\")\n",
    "print(f\"Inherited Houses Shape: {inherited_houses.shape}\")\n",
    "\n",
    "# Display first few rows of the datasets\n",
    "print(\"First few rows of house_data:\")\n",
    "print(house_data.head())\n",
    "print(\"First few rows of inherited_houses:\")\n",
    "print(inherited_houses.head())\n",
    "\n",
    "# Apply log transformation to SalePrice\n",
    "# The sale prices are right-skewed; applying log transformation to normalize the distribution\n",
    "house_data['SalePrice_Log'] = np.log1p(house_data['SalePrice'])\n",
    "\n",
    "# Handle missing values in house_data\n",
    "print(\"\\nHandling missing values in house_data...\")\n",
    "\n",
    "# List of features where missing values likely indicate absence of the feature\n",
    "zero_fill_features = ['2ndFlrSF', 'EnclosedPorch', 'MasVnrArea', 'WoodDeckSF',\n",
    "                      'BsmtFinSF1', 'TotalBsmtSF', '1stFlrSF', 'BsmtUnfSF']\n",
    "\n",
    "for feature in zero_fill_features:\n",
    "    house_data[feature].fillna(0, inplace=True)\n",
    "    print(f\"Filled missing values in {feature} with 0.\")\n",
    "\n",
    "# Fill missing categorical features with mode or default value\n",
    "categorical_mode_fill = {\n",
    "    'BedroomAbvGr': house_data['BedroomAbvGr'].mode()[0],\n",
    "    'BsmtFinType1': 'None',\n",
    "    'GarageFinish': 'Unf',\n",
    "    'BsmtExposure': 'No',\n",
    "    'KitchenQual': 'TA'\n",
    "}\n",
    "\n",
    "for feature, value in categorical_mode_fill.items():\n",
    "    house_data[feature].fillna(value, inplace=True)\n",
    "    print(f\"Filled missing values in {feature} with '{value}'.\")\n",
    "\n",
    "# Fill missing numerical features with median\n",
    "numerical_median_fill = ['GarageYrBlt', 'LotFrontage', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd']\n",
    "\n",
    "for feature in numerical_median_fill:\n",
    "    median_value = house_data[feature].median()\n",
    "    house_data[feature].fillna(median_value, inplace=True)\n",
    "    print(f\"Filled missing values in {feature} with median value {median_value}.\")\n",
    "\n",
    "# Verify that there are no missing values left\n",
    "print(\"\\nChecking for remaining missing values:\")\n",
    "print(house_data.isnull().sum()[house_data.isnull().sum() > 0])\n",
    "\n",
    "# Encode categorical features\n",
    "print(\"\\nEncoding categorical features in house_data...\")\n",
    "\n",
    "# Define mappings for ordinal categorical features based on their definitions\n",
    "ordinal_mappings = {\n",
    "    'BsmtFinType1': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n",
    "    'KitchenQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'BsmtExposure': {'None': 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4},\n",
    "    'GarageFinish': {'None': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3}\n",
    "}\n",
    "\n",
    "for col, mapping in ordinal_mappings.items():\n",
    "    if col in house_data.columns:\n",
    "        house_data[col] = house_data[col].map(mapping)\n",
    "        print(f\"Encoded {col} using ordinal mapping.\")\n",
    "\n",
    "# Identify numeric features\n",
    "numeric_feats = house_data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Check skewness of numeric features\n",
    "skewness = house_data[numeric_feats].apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "print(\"\\nSkewness of numeric features:\")\n",
    "print(skewness)\n",
    "\n",
    "# Features with high skewness (threshold can be adjusted)\n",
    "skewed_features = skewness[abs(skewness) > 0.75].index.tolist()\n",
    "print(\"\\nFeatures with high skewness (|skewness| > 0.75):\")\n",
    "print(skewed_features)\n",
    "\n",
    "# Apply log or box-cox transformation to skewed features\n",
    "print(\"\\nTransforming skewed features in house_data...\")\n",
    "\n",
    "# Dictionary to store lambda values for box-cox transformation\n",
    "lam_dict = {}\n",
    "\n",
    "for feat in skewed_features:\n",
    "    if (house_data[feat] <= 0).any():\n",
    "        # If the feature has zero or negative values, use log1p transformation\n",
    "        house_data[feat] = np.log1p(house_data[feat])\n",
    "        print(f\"Applied log1p transformation to {feat}.\")\n",
    "    else:\n",
    "        # Apply box-cox transformation\n",
    "        try:\n",
    "            transformed_data, lam = boxcox(house_data[feat])\n",
    "            house_data[feat] = transformed_data\n",
    "            lam_dict[feat] = lam\n",
    "            print(f\"Applied box-cox transformation to {feat} with lambda {lam:.4f}.\")\n",
    "        except ValueError:\n",
    "            # If box-cox fails, use log1p\n",
    "            house_data[feat] = np.log1p(house_data[feat])\n",
    "            print(f\"Applied log1p transformation to {feat} (box-cox failed).\")\n",
    "\n",
    "# Save skewed features and lambda values for future use\n",
    "with open(models_dir / 'skewed_features.pkl', 'wb') as f:\n",
    "    pickle.dump(skewed_features, f)\n",
    "with open(models_dir / 'lam_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(lam_dict, f)\n",
    "\n",
    "# Feature engineering\n",
    "print(\"\\nPerforming feature engineering in house_data...\")\n",
    "\n",
    "# Create new features based on domain knowledge\n",
    "house_data['TotalSF'] = house_data['TotalBsmtSF'] + house_data['1stFlrSF'] + house_data['2ndFlrSF']\n",
    "print(\"Created TotalSF feature as sum of TotalBsmtSF, 1stFlrSF, and 2ndFlrSF.\")\n",
    "\n",
    "house_data['Qual_TotalSF'] = house_data['OverallQual'] * house_data['TotalSF']\n",
    "print(\"Created Qual_TotalSF feature as product of OverallQual and TotalSF.\")\n",
    "\n",
    "# Prepare data for modeling\n",
    "print(\"\\nPreparing data for modeling...\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "X = house_data.drop(['SalePrice', 'SalePrice_Log'], axis=1, errors='ignore')\n",
    "y = house_data['SalePrice_Log']\n",
    "\n",
    "# Define the features based on the provided metadata\n",
    "feature_list = [\n",
    "    '1stFlrSF', '2ndFlrSF', 'BedroomAbvGr', 'BsmtExposure', 'BsmtFinType1',\n",
    "    'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', 'GarageArea', 'GarageFinish',\n",
    "    'GarageYrBlt', 'GrLivArea', 'KitchenQual', 'LotArea', 'LotFrontage',\n",
    "    'MasVnrArea', 'EnclosedPorch', 'OpenPorchSF', 'OverallCond', 'OverallQual',\n",
    "    'WoodDeckSF', 'YearBuilt', 'YearRemodAdd', 'TotalSF', 'Qual_TotalSF'  # Include engineered features\n",
    "]\n",
    "\n",
    "# Ensure the features are in X\n",
    "X = X[feature_list]\n",
    "\n",
    "# Feature selection using Random Forest\n",
    "print(\"\\nPerforming feature selection using Random Forest...\")\n",
    "\n",
    "# Use Random Forest to estimate feature importances\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(\"Feature importances from Random Forest:\")\n",
    "print(importances)\n",
    "\n",
    "# Select top features (e.g., top 20)\n",
    "selected_features = importances[:20].index.tolist()\n",
    "print(\"\\nSelected top features for modeling:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Save selected features for future use\n",
    "with open(models_dir / 'selected_features.pkl', 'wb') as f:\n",
    "    pickle.dump(selected_features, f)\n",
    "\n",
    "# Keep only selected features\n",
    "X = X[selected_features]\n",
    "\n",
    "# Split data into training and test sets\n",
    "print(\"\\nSplitting data into training and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save train and test data for the dashboard\n",
    "joblib.dump((X_train, X_test, y_train, y_test), models_dir / 'train_test_data.joblib')\n",
    "\n",
    "# Scaling features\n",
    "print(\"\\nScaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, models_dir / 'scaler.joblib')\n",
    "\n",
    "# Model training\n",
    "print(\"\\nTraining models...\")\n",
    "\n",
    "# Adjusted alpha values for Ridge Regression and Lasso Regression to avoid numerical instability\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': RidgeCV(alphas=np.logspace(-3, 3, 7), cv=5),\n",
    "    'ElasticNet': ElasticNetCV(alphas=np.logspace(-4, -0.5, 30), l1_ratio=[0.1, 0.5, 0.9], cv=5, max_iter=10000),\n",
    "    'Lasso Regression': LassoCV(alphas=np.logspace(-3, -0.5, 30), cv=5, max_iter=10000),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=3,\n",
    "        min_samples_leaf=5, max_features=0.8, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=100, max_depth=None, max_features='sqrt',\n",
    "        min_samples_leaf=2, random_state=42),\n",
    "    'XGBoost': XGBRegressor(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=5,\n",
    "        min_child_weight=3, subsample=0.8, colsample_bytree=0.8, random_state=42)\n",
    "}\n",
    "\n",
    "# Model evaluation\n",
    "print(\"\\nEvaluating models...\")\n",
    "results = {'Model': [], 'MAE': [], 'RMSE': [], 'R² Score': []}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    model_filename = f\"{name.replace(' ', '_').lower()}_model.joblib\"\n",
    "    # Save the trained model\n",
    "    joblib.dump(model, os.path.join(models_dir, model_filename))\n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    # Calculate performance metrics\n",
    "    y_test_exp = np.expm1(y_test)\n",
    "    predictions_exp = np.expm1(predictions)\n",
    "    # Handle any negative predictions due to model limitations\n",
    "    predictions_exp[predictions_exp < 0] = 0\n",
    "    mae = mean_absolute_error(y_test_exp, predictions_exp)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_exp, predictions_exp))\n",
    "    r2 = r2_score(y_test_exp, predictions_exp)\n",
    "    # Store results\n",
    "    results['Model'].append(name)\n",
    "    results['MAE'].append(mae)\n",
    "    results['RMSE'].append(rmse)\n",
    "    results['R² Score'].append(r2)\n",
    "    print(f\"{name} - MAE: {mae:.2f}, RMSE: {rmse:.2f}, R² Score: {r2:.4f}\")\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(os.path.join(models_dir, 'model_evaluation.csv'), index=False)\n",
    "\n",
    "# Save feature importances\n",
    "# Using the 'importances' Series from Random Forest\n",
    "feature_importances = importances.reset_index()\n",
    "feature_importances.columns = ['Feature', 'Importance']\n",
    "feature_importances.to_csv(os.path.join(models_dir, 'feature_importances.csv'), index=False)\n",
    "print(\"\\nSaved feature importances to 'feature_importances.csv'.\")\n",
    "\n",
    "# Process inherited houses\n",
    "print(\"\\nProcessing inherited houses...\")\n",
    "\n",
    "# Handle missing values in inherited_houses\n",
    "print(\"Handling missing values in inherited_houses...\")\n",
    "for feature in zero_fill_features:\n",
    "    inherited_houses[feature].fillna(0, inplace=True)\n",
    "    print(f\"Filled missing values in {feature} with 0.\")\n",
    "\n",
    "for feature, value in categorical_mode_fill.items():\n",
    "    inherited_houses[feature].fillna(value, inplace=True)\n",
    "    print(f\"Filled missing values in {feature} with '{value}'.\")\n",
    "\n",
    "for feature in numerical_median_fill:\n",
    "    median_value = house_data[feature].median()\n",
    "    inherited_houses[feature].fillna(median_value, inplace=True)\n",
    "    print(f\"Filled missing values in {feature} with median value {median_value}.\")\n",
    "\n",
    "# Encode categorical features\n",
    "print(\"Encoding categorical features in inherited_houses...\")\n",
    "for col, mapping in ordinal_mappings.items():\n",
    "    if col in inherited_houses.columns:\n",
    "        inherited_houses[col] = inherited_houses[col].map(mapping)\n",
    "        print(f\"Encoded {col} using ordinal mapping.\")\n",
    "\n",
    "# Feature engineering on inherited houses\n",
    "print(\"Performing feature engineering on inherited_houses...\")\n",
    "inherited_houses['TotalSF'] = inherited_houses['TotalBsmtSF'] + inherited_houses['1stFlrSF'] + inherited_houses['2ndFlrSF']\n",
    "print(\"Created TotalSF feature.\")\n",
    "inherited_houses['Qual_TotalSF'] = inherited_houses['OverallQual'] * inherited_houses['TotalSF']\n",
    "print(\"Created Qual_TotalSF feature.\")\n",
    "\n",
    "# Transform skewed features\n",
    "print(\"\\nTransforming skewed features in inherited_houses...\")\n",
    "for feat in skewed_features:\n",
    "    if feat in inherited_houses.columns:\n",
    "        if (inherited_houses[feat] <= 0).any():\n",
    "            inherited_houses[feat] = np.log1p(inherited_houses[feat])\n",
    "            print(f\"Applied log1p transformation to {feat}.\")\n",
    "        else:\n",
    "            lam = lam_dict.get(feat)\n",
    "            if lam is not None:\n",
    "                try:\n",
    "                    inherited_houses[feat] = boxcox(inherited_houses[feat], lam)\n",
    "                    print(f\"Applied box-cox transformation to {feat} with lambda {lam:.4f}.\")\n",
    "                except ValueError:\n",
    "                    inherited_houses[feat] = np.log1p(inherited_houses[feat])\n",
    "                    print(f\"Applied log1p transformation to {feat} (box-cox failed).\")\n",
    "            else:\n",
    "                inherited_houses[feat] = np.log1p(inherited_houses[feat])\n",
    "                print(f\"Applied log1p transformation to {feat} (no lambda found).\")\n",
    "\n",
    "# Ensure the features match\n",
    "inherited_houses = inherited_houses.reindex(columns=selected_features, fill_value=0)\n",
    "print(\"\\nReindexed inherited_houses to match selected features.\")\n",
    "\n",
    "# Scaling\n",
    "print(\"Scaling inherited houses features...\")\n",
    "inherited_houses_scaled = scaler.transform(inherited_houses)\n",
    "\n",
    "# Predictions\n",
    "print(\"\\nMaking predictions on inherited houses...\")\n",
    "predictions_df = pd.DataFrame()\n",
    "for name, model in models.items():\n",
    "    predictions_log = model.predict(inherited_houses_scaled)\n",
    "    predictions_actual = np.expm1(predictions_log)\n",
    "    # Handle negative predictions\n",
    "    predictions_actual[predictions_actual < 0] = 0\n",
    "    # Store predictions\n",
    "    predictions_df[name] = predictions_actual\n",
    "    print(f\"Predictions made using {name}.\")\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions_df.to_csv(os.path.join(models_dir, 'inherited_houses_predictions.csv'), index=False)\n",
    "print(\"\\nPredictions saved to 'inherited_houses_predictions.csv'.\")\n",
    "\n",
    "# Optional: Display the predictions\n",
    "print(\"\\nPredictions for Inherited Houses:\")\n",
    "print(predictions_df)\n",
    "\n",
    "# Save the final model (best performing model)\n",
    "best_model_name = results_df.sort_values('RMSE').iloc[0]['Model']\n",
    "print(f\"\\nBest performing model is {best_model_name}. Saving as final_model.joblib.\")\n",
    "joblib.dump(models[best_model_name], os.path.join(models_dir, 'final_model.joblib'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
